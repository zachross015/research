\chapter{\sectioncite{semidefinite}}
\label{sec:semidefinite}

The initial problem attempted to be solved by this paper is creating an
approximation algorithm for \textsc{Max-Cut} to improve on the previous
guarantee of $\frac{3}{4}$ for an undirected graph $G = (V, E)$ where $|V| = n$
with nonnegative weights $W_{ij} = W_{ji}$ i.e. $\mat{W}$ denotes a weighted
adjacency matrix. 

We construct a cut of $G$ by assigning to each $i \in V$ a value $y_i \in \{-1,
1\}$ and construct $S \subset G$ by taking $S = \{i | y_i = 1\}$.
Define the value of a cut as 
\begin{equation}
    \label{eq:weightc}
    w(S, \bar{S}) = \frac{1}{2} \sum_{i < j} W_{ij} (1 - y_iy_j) 
\end{equation}
The \textsc{Max-Cut} integer quadratic program is then originally defined as 
\begin{equation}
    \label{eq:maxc}
    \textsc{Max Cut}(G) = \max_{S \subset V} w(S, \bar{S}), 
\end{equation} i.e.\ the goal is to find values $y_i$ for all $i \in V$ that
maximize this equation.

The proposed relaxation is to substitute each $y_i$ in \refeq{weightc} with some
vector $\vec{v_i} \in \R^m$ ($m \leq n$) such that $\norm{\vec{v_i}}^2 = 1$ so
that each $\vec{v_i}$ belongs to
the $m$-dimensional unit sphere $S_m$. Under this relaxation, we instead
construct $S \subset G$ by selecting some $\vec{r} \in S_m$ randomly and uniformly and
take $S = \{i | \dotp{\vec{v_i}, \vec{r}} \geq 0\}$ i.e. $\vec{r}$ determines a hyperplane which
separates vertices of $G$. Then \refeq{weightc} becomes
\begin{equation}
    \label{eq:weightp}
    w(S, \bar{S}) = \frac{1}{2} \sum_{i < j} W_{ij} (1 - \dotp{\vec{v_i}, \vec{v_j}}) .
\end{equation} 

The goal is now to determine optimal values for the unit vectors $\vec{v_1}, \dots,
\vec{v_n}$ and the dimensionality $m$ for the vector space they reside. We can take
$\mat{B}
= \bmat{\vec{v_1} & \dots & \vec{\v_n}}$ so that $\mat{Y} = \mat{B}^\intercal
\mat{B}$ is the Gram matrix of $\mat{B}$. Instead of solving for $\mat{B}$ right
away, we can instead note that each $Y_{ij} = \dotp{\vec{v_i}, \vec{v_j}}$ and
that our previous constraint is now just the constraint $Y_{ii} = 1$. We also
have that $Y$ is symmetric by definition and is therefore PSD. Semidefinite
programming can be used to maximize the equation 
\begin{equation}
    \frac{1}{2} \sum_{i < j}w_{ij}(1 - Y_{ij}).
\end{equation} Rather than deal with each $v_i$ directly, we can just use an
approximate semidefinite programming algorithm to find an optimal $Y$ in
$O\left(\sqrt{n}\left(\log\left(\sum_{i < j}w_ij\right) + \log 1 /
\epsilon\right)\right)$ iterations (Alizadeh's adaptation of Ye's interior-point
algorithm) with each iteration taking $O(n^3)$, where $\epsilon > 0$ denotes the
acceptable distance from the optimal value $Z_P^*$ (i.e.\ $Z_P^* - \epsilon$).
Once an optimal $\mat{Y}$ has been found, an incomplete Cholesky decomposition
can be used to obtain $\vec{v_1}, \dots, \vec{v_n} \in S_m$ s.t. 
\begin{equation}
    \frac{1}{2} \sum_{i < j} w_{ij} (1 - \dotp{\vec{\v_i}, \vec{\v_j}}) \geq
    Z_P^* - \epsilon.
\end{equation} To find $m$, they note that any \emph{extreme solution}, one
which cannot be expressed as the strict convex combination of other feasible
solutions, has at most rank $l$ where
\begin{equation}
    l \leq \frac{\sqrt{8n + 1} - 1}{2} < \sqrt{2n}.
\end{equation}. Any other solution has $m < \sqrt{2n}$.
