\begin{research} 
    Is is a problem that we assume lower layers of the NN are unaffected by
    upper layers? Especially with regards to gradient descent, we formulate the
    lower layer's direction in terms of a recursive formula from the upper
    layer, so that each layer is technically dependent on the others. So what if
    we described gradient descent as being reliant on the output of all layers?
    Or is there a way to update gradients independent of the other layers? 

\end{research}
