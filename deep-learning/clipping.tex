\section{\sectioncite{clipping}}
\label{cha:clipping}

This paper considers the class of problems dealing with the minimization of 
\begin{equation}
    \min_{x \in \R^n} f(x) \qquad \text{where} \qquad f(x) = \frac{1}{m} \sum_{i
    = 1}^m f_i(x),
\end{equation} where $f_i : \R^n \rightarrow \R$ are differentiable, non-convex
functions. As a side note, this differs from notation that I'm used to, in
that $x$ is considered to be the set of parameters while $i$, or more
importantly $f_i$, is a function of the parameters using the $i^{\text{th}}$
component of the dataset to measure the loss. That is, the function $f_i(x)$
determines the loss accumulated when using $x$ as the set of parameters on input
$i$. $f$ is said to be the \emph{objective function} while each $f_i$ is called
a \emph{component function}.

The incremental method for SGD is 
\begin{equation}
    x_{k+1} = x_{k}  - \alpha_k \grad f_{i_k}(x_k) \quad k= 0, 1, \dots
\end{equation} where $x_k$ is the values of the parameters at ieration $k$,
$\alpha_k$ is the learning rate, and $f_{i_k}$ is a uniform randomly chosen
component function $i_k \in \{1, 2, \dots, m\}$ of the dataset. The incremental
method for IGC is 
\begin{equation}
    x_{k, i} = x_{k, i -1} - \alpha_k \grad f_i(x_{k, i - 1}) \quad i = 1,
    \dots, m \quad k = 0, 1, \dots
\end{equation} where the recursion is defined by base case $x_{0, 0}$ and
iterative step $x_{k, 0} = x_{k - 1, m}$ and is more cyclical by nature. 

The clipping function $\cal{C} : \R^n \rightarrow \R^n$ with clipping threshold
parameter $\eta > 0$ is defined by 
\begin{equation}
    \cal{C}(g;\eta) = \min\left\{1, \frac{\eta}{\norm{g}}\right\} \cdot g.
\end{equation} Our iterative methods can take advantage of clipping by clipping
the gradient so that SGD with clipping is 
\begin{equation}
    \label{eq:sgdclip}
    x_{k+1} = x_{k}  - \alpha_k \cal{C}(\grad f_{i_k}(x_k); \eta),
\end{equation} and IGC with clipping is 
\begin{equation}
    x_{k, i} = x_{k, i -1} - \alpha_k \cal{C}(\grad f_i(x_{k, i - 1}); \eta), 
\end{equation} and is written iteratively (using the notation $x_k = x_{k,0} =
x_{k - 1, m}$) as 
\begin{equation}
    \label{eq:igcclip}
    x_{k + 1} = x_{k} - \alpha_k \sum_{i = 1}^m\cal{C}(\grad f_i(x_{k, i - 1}); \eta), 
\end{equation}

For the theoretical understanding of the clipping function's effects on the
convergence of both SGD and IGC, we make the following assumptions:
\begin{description}
    \item[Bounded below] there exists an $f^*$ such that for all $x \in \R^n$,
        $f(x) \geq f^*$;
    \item[Relaxed smoothness] there exist constants $L_0, L_1 \in \R^+$ such
        that $\norm{\grad^2f(x)} \leq L_0 + L_1 \norm{\grad f(x)}$.
\end{description} The second condition becomes Lipschitz smoothness when $L_1 =
0$. Let $f_k = f(x_k)$ and assume for simplicity from here on out that SGD and
IGC have a constant step size $\alpha$ and that IGC's notation for $x_{k, i}$
can be simplified for $x_{k, 0}$ to $x_k$. The paper shows that convergence for
the algorithm can be ensured if there exists a constant $C$ such that 
\begin{equation}
    \label{eq:neccond}
    \dotp{\sum_{i = 1}^m \cal{C}(\grad f_i(x_k); \eta), \grad f_k} \geq C
        \norm{\grad f_k}^2
\end{equation} i.e.\ if the magnitude of the clipped gradient projected in the
direction of the regular gradient is bounded below by the magnitude of the
regular gradient. This value is simplified further as follows.

Let $g_{ki} = \grad f_i(x_k)$ and note the following properties of $g_{ki}$
\begin{equation}
    g_{ki} = \beta_{ki}\grad f_k + t_{ki} \quad \text{where} \quad
    \begin{aligned}
        &\beta_{ki} = \frac{\dotp{g_{ki}, \grad f_k}}{\norm{\grad f_k}^2} =
        \frac{\norm{g_{ki}}}{\norm{\grad f_k}} \cos \theta_{ki} \\ \\
        &t_{ki} \in \grad f_k^{\perp} = \{ z | \dotp{z, \grad f_k} = 0\}
    \end{aligned}.
\end{equation} Since $\frac{1}{m}\sum_{i}^m g_{ki} = \grad f_k$, it is a
necessary condition that $\sum_{i}^m \beta_{ki} = m$ and $\sum_{i}^m t_{ki} =
0$. Let $\gamma_{ki} = \min\{1, \eta/\norm{g_{ki}}\}$ and note that
$\cal{C}(g_{ki}; \eta) = \gamma_{ki}g_{ki}$. The paper then shows that 
\begin{equation}
    \dotp{\sum_{i = 1}^m \cal{C}(\grad f_i(x_k); \eta), \grad f_k} = \sum_{i =
    1}^m \gamma_{ki}\beta_{ki}\norm{\grad f_k}^2.
\end{equation} so that \refeq{neccond} becomes 
\begin{equation}
    \label{eq:conv}
    \sum_{i = 1}^m \gamma_{ki}\beta_{ki} \geq C,
\end{equation} that is, \emph{the necessary condition for convergence is that
the sum in \refeq{conv} is greater than some positive scalar $C$}.

There are then essentially two conditions, either of which will ensure the
convergence of our algorithm:
\begin{enumerate}
    \item all $g_{ki}$ can be partitioned into pairs so that if $g_{kj}$ and
        $g_{kl}$ are a pair then $\beta_{kj} + \beta_{kl} > 0$ and $\norm{t_{kj}} = \norm{t_{kl}}$;
    \item all $\beta_{ki} > 0$ or equivalently all $\cos \theta_{ki} > 0$.
\end{enumerate}
Under the second condition, the paper then shows that a lower bound can be
derived making use of the minimum and maximum gradient magnitudes w.r.t.\ an
example $i$. That is, if we let $m_g = \min_i \norm{g_{ki}}$ and $M_g = \max_i
\norm{g_{ki}}$, and we let constants $c_1$ and $c_2$ be defined by the
inequalities
\begin{equation}
    0 < c_1 \leq \frac{1}{m} \sum_{i = 1}^m \cos \theta_{ki} \quad \text{and}
    \quad 0 < c_2 \leq \frac{m_g}{M_g},
\end{equation} then the lower bounds for \refeq{neccond} are then divided into
three scenarios:
\begin{enumerate}
    \item if $\eta \geq M_g$, then 
        \begin{equation}
             \dotp{\sum_{i = 1}^m \cal{C}(\grad f_i(x_k); \eta), \grad f_k} =
             m\norm{\grad f_k}^2;
        \end{equation}
        \item if $\eta \leq m_g$, then 
            \begin{equation}
                \dotp{\sum_{i = 1}^m \cal{C}(\grad f_i(x_k); \eta), \grad f_k} =
                \left(\eta\sum_{i =1}^m \cos\theta_{ki}\right)\norm{\grad f_k};
            \end{equation}
        \item and if $m_g < \eta < M_g$, then
            \begin{equation}
                \dotp{\sum_{i = 1}^m \cal{C}(\grad f_i(x_k); \eta), \grad f_k} 
                \geq m \min\{\eta c_1, c_2\norm{\grad f_k}\} \norm{\grad f_k}.
            \end{equation}
\end{enumerate}

The paper concludes by providing the following theorems on the behavior of SGD
and IGC with gradient clipping.
\begin{theorem}
    Assuming that we have a lower bound and relaxed smoothness, if 
    \begin{equation}
        \alpha \leq \frac{c_1}{4\eta L_1}
    \end{equation}
    then the iterates $\{x_k\}$ generated by \refeq{sgdclip} satisfy
    \begin{equation}
        \frac{1}{T+1}\sum_{k = 0}^T \min\{\eta c_1, c_2\norm{\grad f_k}\} \norm{\grad f_k}
        \leq \frac{2(f_0 - f^*)}{(T+1)\alpha} + 5 \alpha \eta^2 L_0 +
        \frac{\alpha\eta^3 L_1 c_1}{c_2}.
    \end{equation}
\end{theorem}
\begin{theorem}
    Assuming that we have a lower bound, relaxed smoothness, and each
    component function also satisfies relaxed smoothness i.e. 
    \begin{equation}
        \norm{\grad^2 f_i(x)} \leq L_{0i} + L_{1i}\norm{\grad f_i(x)}, \quad i =
        1, \dots, m;
    \end{equation} if 
    \begin{equation}
        \alpha \leq \min \left\{\frac{c_1}{2m(2\eta L_1 + G)},
        \frac{1}{5mL_{0i}}, \frac{1}{8m\eta L_1i} \right\}, \quad i = 1, \dots,
        m;
    \end{equation} then the iterates $\{x_k\}$ generated by \refeq{igcclip}
    satisfy 
    \begin{equation}
        \frac{1}{T+1}\sum_{k = 0}^T \min\{\eta c_1, c_2\norm{\grad f_k}\} \norm{\grad f_k}
        \leq
        \frac{2(f_0 - f^*)}{(T+1)\alpha m} + 5 \alpha m \eta^2 L_0 +
        \frac{\alpha m \eta^2 c_1(2 \eta L_1 + G)}{2c_2},
    \end{equation} where 
    \begin{equation}
        G = 5 \max_{1 \leq i \leq m} L_{0i} + 16\eta \max_{1 \leq i \leq m}
        L_{1i}.
    \end{equation}
\end{theorem}

